services:
  message-broker:
    build:
      context: ./containers/message-broker/
    container_name: message-broker
    hostname: message-broker
    restart: unless-stopped
    environment:
      RABBITMQ_DEFAULT_USER: ${PLANKWEB_SERVICE_USER}
      RABBITMQ_DEFAULT_PASS: ${PLANKWEB_SERVICE_PASS}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - rabbitmq:/var/lib/rabbitmq
    healthcheck:
      test: rabbitmq-diagnostics -q status
      interval: 30s
      timeout: 30s
      retries: 3

  id-database:
    image: redis:7.4.2
    container_name: id-database
    restart: unless-stopped
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - redis:/data
    healthcheck:
      test: redis-cli info
      interval: 30s
      timeout: 30s
      retries: 3
    user: redis
    command: |
      redis-server
        --requirepass ${PLANKWEB_SERVICE_PASS}
        --save 300 1
        --loglevel warning

  celery-backend:
    image: redis:7.4.2
    container_name: celery-backend
    hostname: celery-backend
    restart: unless-stopped
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - celery:/data
    healthcheck:
      test: redis-cli info
      interval: 30s
      timeout: 30s
      retries: 3
    user: redis
    command: |
      redis-server
        --requirepass ${PLANKWEB_SERVICE_PASS}
        --save 300 1
        --loglevel warning

  executor-http-api:
    build:
      context: ./containers/executor-http-api/
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: apache
    restart: unless-stopped
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - foldseek:/usr/local/apache2/htdocs/data/ds_foldseek
      - p2rank:/usr/local/apache2/htdocs/data/ds_p2rank
      - plank:/usr/local/apache2/htdocs/data/ds_plank
      - conservation:/usr/local/apache2/htdocs/data/conservation
      - inputs:/usr/local/apache2/htdocs/data/inputs
      - tmp:/usr/local/apache2/htdocs/tmp
    healthcheck:
      test: curl -f http://localhost/server-status?auto
      interval: 30s
      timeout: 30s
      retries: 3
    command: httpd -D FOREGROUND

  id-provider: 
    build:
      context: ./containers
      dockerfile: ./id-provider/Dockerfile
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: id-provider
    restart: unless-stopped
    depends_on:
      id-database:
        condition: service_healthy
    environment:
      REDIS_PASS: ${PLANKWEB_SERVICE_PASS}
      LOGGING_TZ: ${PLANKWEB_TIMEZONE:-Europe/Prague}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    command: gunicorn -w 2 -b :5000 id-provider:app --log-level warning

  gateway:
    build:
      context: ./
      dockerfile: ./containers/gateway/Dockerfile
      args:
        WEB_SERVICE_USER: ${PLANKWEB_SERVICE_USER}
        WEB_SERVICE_PASS: ${PLANKWEB_SERVICE_PASS}
        VITE_API_BASE_URL: ${PLANKWEB_URL}
    container_name: gateway
    restart: unless-stopped
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    depends_on:
      executor-http-api:
        condition: service_healthy
      http-server:
        condition: service_started
      swagger-ui:
        condition: service_started
    ports:
      - 127.0.0.1:9864:80

  http-server:
    build:
      context: ./containers
      dockerfile: ./http-server/Dockerfile
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: http-server
    restart: unless-stopped
    depends_on:
      id-provider:
        condition: service_started
      message-broker:
        condition: service_healthy
      celery-backend:
        condition: service_healthy
      executor-http-api:
        condition: service_healthy
      metatask:
        condition: service_started
    environment:
      CELERY_NAME: plankweb_tasks
      CELERY_BROKER_URL: amqp://${PLANKWEB_SERVICE_USER}:${PLANKWEB_SERVICE_PASS}@message-broker:5672// 
      APACHE_URL: http://apache:80/
      ID_PROVIDER_URL: http://id-provider:5000/generate
      LOGGING_TZ: ${PLANKWEB_TIMEZONE:-Europe/Prague}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - tmp:/app/tmp
    command: gunicorn -w 4 -b :3000 http-server:app --log-level warning

  ds-foldseek:
    build:
      context: ./containers
      dockerfile: ./data-source-executors/executor-foldseek/Dockerfile
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: ds-foldseek
    restart: unless-stopped
    depends_on:
      message-broker:
        condition: service_healthy
      celery-backend:
        condition: service_healthy
      executor-http-api:
        condition: service_healthy
    environment:
      CELERY_NAME: plankweb_tasks
      CELERY_BROKER_URL: amqp://${PLANKWEB_SERVICE_USER}:${PLANKWEB_SERVICE_PASS}@message-broker:5672// 
      INPUTS_URL: http://apache:80/data/inputs
      PLANKWEB_BASE_URL: ${PLANKWEB_URL}
      FOLDSEEK_SIM_PROTS: 1000
      LOGGING_TZ: ${PLANKWEB_TIMEZONE:-Europe/Prague}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - foldseek:/app/results
    command: |
      celery
        --app=celery_worker worker
        --queues=ds_foldseek
        --hostname=foldseek_worker 
        --loglevel=warning
        --concurrency=4
        --events

  ds-p2rank:
    build:
      context: ./containers
      dockerfile: ./data-source-executors/executor-p2rank/Dockerfile
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: ds-p2rank
    restart: unless-stopped
    depends_on:
      message-broker:
        condition: service_healthy
      celery-backend:
        condition: service_healthy
      executor-http-api:
        condition: service_healthy
    environment:
      CELERY_NAME: plankweb_tasks
      CELERY_BROKER_URL: amqp://${PLANKWEB_SERVICE_USER}:${PLANKWEB_SERVICE_PASS}@message-broker:5672//
      INPUTS_URL: http://apache:80/data/inputs
      CONSERVATION_URL: http://apache:80/data/conservation
      PLANKWEB_BASE_URL: ${PLANKWEB_URL}
      LOGGING_TZ: ${PLANKWEB_TIMEZONE:-Europe/Prague}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - p2rank:/app/results
    command: |
      celery
        --app=celery_worker worker
        --queues=ds_p2rank
        --hostname=p2rank_worker
        --loglevel=warning
        --concurrency=4
        --events

  ds-plank:
    build:
      context: ./containers
      dockerfile: ./data-source-executors/executor-plank/Dockerfile
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: ds-plank
    restart: unless-stopped
    depends_on:
      message-broker:
        condition: service_healthy
      celery-backend:
        condition: service_healthy
      executor-http-api:
        condition: service_healthy
    environment:
      CELERY_NAME: plankweb_tasks
      CELERY_BROKER_URL: amqp://${PLANKWEB_SERVICE_USER}:${PLANKWEB_SERVICE_PASS}@message-broker:5672// 
      INPUTS_URL: http://apache:80/data/inputs
      PLANKWEB_BASE_URL: ${PLANKWEB_URL}
      LOGGING_TZ: ${PLANKWEB_TIMEZONE:-Europe/Prague}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - plank:/app/results
    command: |
      celery
        --app=celery_worker worker
        --queues=ds_plank
        --hostname=plank_worker 
        --loglevel=warning
        --concurrency=4
        --events

  conservation:
    build:
      context: ./containers
      dockerfile: ./conservation/Dockerfile
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: conservation
    restart: unless-stopped
    depends_on:
      message-broker:
        condition: service_healthy
      executor-http-api:
        condition: service_healthy
    environment:
      CELERY_NAME: plankweb_tasks
      CELERY_BROKER_URL: amqp://${PLANKWEB_SERVICE_USER}:${PLANKWEB_SERVICE_PASS}@message-broker:5672//
      CELERY_BACKEND_URL: redis://:${PLANKWEB_SERVICE_PASS}@celery-backend:6379/0
      INPUTS_URL: http://apache:80/data/inputs
      LOGGING_TZ: ${PLANKWEB_TIMEZONE:-Europe/Prague}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - conservation:/app/results
    command: |
      celery
        --app=celery_worker worker
        --queues=conservation
        --hostname=conservation_worker
        --loglevel=warning
        --concurrency=4
        --events

  converter:
    build:
      context: ./containers
      dockerfile: ./converter/Dockerfile
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: converter
    restart: unless-stopped
    depends_on:
      message-broker:
        condition: service_healthy
      celery-backend:
        condition: service_healthy
      executor-http-api:
        condition: service_healthy
    environment:
      CELERY_NAME: plankweb_tasks
      CELERY_BROKER_URL: amqp://${PLANKWEB_SERVICE_USER}:${PLANKWEB_SERVICE_PASS}@message-broker:5672// 
      CELERY_BACKEND_URL: redis://:${PLANKWEB_SERVICE_PASS}@celery-backend:6379/0
      INPUTS_URL: http://apache:80/data/inputs
      LOGGING_TZ: ${PLANKWEB_TIMEZONE:-Europe/Prague}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    command: |
      celery
        --app=celery_worker worker
        --queues=converter
        --hostname=converter_worker
        --loglevel=warning
        --concurrency=4
        --events

  metatask:
    build:
      context: ./containers
      dockerfile: ./metatask/Dockerfile
      args:
        UID: ${PLANKWEB_DEFAULT_UID}
        GID: ${PLANKWEB_DEFAULT_GID}
    container_name: metatask
    restart: unless-stopped
    depends_on:
      message-broker:
        condition: service_healthy
      celery-backend:
        condition: service_healthy
      executor-http-api:
        condition: service_healthy
      converter:
        condition: service_started
      conservation:
        condition: service_started
      ds-foldseek:
        condition: service_started
      ds-p2rank:
        condition: service_started
      ds-plank:
        condition: service_started
    environment:
      CELERY_NAME: plankweb_tasks
      CELERY_BROKER_URL: amqp://${PLANKWEB_SERVICE_USER}:${PLANKWEB_SERVICE_PASS}@message-broker:5672// 
      CELERY_BACKEND_URL: redis://:${PLANKWEB_SERVICE_PASS}@celery-backend:6379/0
      APACHE_URL: http://apache:80/data
      LOGGING_TZ: ${PLANKWEB_TIMEZONE:-Europe/Prague}
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - inputs:/app/inputs
    command: |
      celery
        --app=metatask worker
        --queues=metatask
        --hostname=metatask_worker
        --loglevel=warning
        --concurrency=4
        --pool=threads
        --events

  flower:
    build: https://github.com/mher/flower.git
    container_name: flower
    restart: unless-stopped
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    depends_on:
      message-broker:
        condition: service_healthy
      metatask:
        condition: service_started
    environment:
      CELERY_BROKER_URL: amqp://${PLANKWEB_SERVICE_USER}:${PLANKWEB_SERVICE_PASS}@message-broker:5672//
    command: celery flower --url_prefix=service/flower

  gateway-exporter:
    image: nginx/nginx-prometheus-exporter:1.4.1
    container_name: gateway-exporter
    restart: unless-stopped
    depends_on:
      gateway:
        condition: service_started
    command: --nginx.scrape-uri=http://gateway:8080/nginx_status

  id-database-exporter: 
    image: oliver006/redis_exporter:v1.70.0
    container_name: id-database-exporter
    restart: unless-stopped
    depends_on:
      id-database:
        condition: service_started
    environment:
      REDIS_ADDR: redis://:${PLANKWEB_SERVICE_PASS}@id-database:6379/0

  celery-backend-exporter:
    image: oliver006/redis_exporter:v1.70.0
    container_name: celery-backend-exporter
    restart: unless-stopped
    depends_on:
      celery-backend:
        condition: service_healthy
    environment:
      REDIS_ADDR: redis://:${PLANKWEB_SERVICE_PASS}@celery-backend:6379/0

  executor-http-api-exporter:
    image: bitnami/apache-exporter:1.0.10
    container_name: apache-exporter
    restart: unless-stopped
    depends_on:
      executor-http-api:
        condition: service_started
    command: --scrape_uri=http://apache:80/server-status?auto

  prometheus:
    image: prom/prometheus:v3.3.0
    container_name: prometheus
    restart: unless-stopped
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    depends_on:
      gateway-exporter:
        condition: service_started
      id-database-exporter:
        condition: service_started
      celery-backend-exporter:
        condition: service_started
      executor-http-api-exporter:
        condition: service_started
      message-broker:
        condition: service_started
      flower:
        condition: service_started
    volumes:
      - ./containers/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.external-url=http://gateway:80/service/prometheus/

  vector:
    image: timberio/vector:0.45.0-debian
    container_name: vector
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - ./containers/monitoring/vector.yaml:/etc/vector/vector.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    depends_on:
      id-provider:
        condition: service_started
      converter:
        condition: service_started
      conservation:
        condition: service_started
      ds-foldseek:
        condition: service_started
      ds-p2rank:
        condition: service_started
      ds-plank:
        condition: service_started
      metatask:
        condition: service_started
      http-server:
        condition: service_started
      loki:
        condition: service_started

  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    restart: unless-stopped
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    command: -config.file=/etc/loki/local-config.yaml

  grafana:
    image: grafana/grafana:11.6.0
    container_name: grafana
    restart: unless-stopped
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    depends_on:
      prometheus:
        condition: service_started
      loki:
        condition: service_started
    environment:
      GF_SECURITY_ADMIN_USER: ${PLANKWEB_SERVICE_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${PLANKWEB_SERVICE_PASS}
      GF_SERVER_ROOT_URL: http://gateway:80/service/grafana/
      GF_SERVER_SERVE_FROM_SUB_PATH: true
    volumes:
      - grafana:/var/lib/grafana
  
  swagger-ui:
    image: swaggerapi/swagger-ui
    container_name: openapi
    restart: unless-stopped
    environment:
      SWAGGER_JSON: /app/swagger.yaml
    logging:
      options:
        max-size: "50m"
        max-file: "5"
    volumes:
      - ./swagger.yaml:/app/swagger.yaml:ro

volumes:
  rabbitmq:
    external: True
    name: plankweb_rabbitmq
  redis:
    external: True
    name: plankweb_redis
  celery:
    external: True
    name: plankweb_celery
  foldseek:
    external: True
    name: plankweb_foldseek
  p2rank:
    external: True
    name: plankweb_p2rank
  plank:
    external: True
    name: plankweb_plank
  inputs:
    external: True
    name: plankweb_inputs
  conservation:
    external: True
    name: plankweb_conservation
  grafana:
    external: True
    name: plankweb_grafana
  tmp:
    external: True
    name: plankweb_tmp
